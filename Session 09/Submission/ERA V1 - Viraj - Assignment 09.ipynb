{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "bw8mN4mWaJwt"
      },
      "source": [
        "# Assignment 9\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "i5EJaJ6PaJwu"
      },
      "source": [
        "## Library Installation (Optional)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "cm_GkK-maJwv"
      },
      "outputs": [],
      "source": [
        "# Where are you running this? Can be either 'local' or 'colab'\n",
        "model_run_location = \"local\"\n",
        "\n",
        "# # Do you want to install the required packages?\n",
        "# install_required_packages = False\n",
        "install_required_packages = False if model_run_location == \"local\" else True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ehhA4GGpaJww",
        "outputId": "e2ebc6c7-e2d5-4662-dfb8-3fb2d95941be"
      },
      "outputs": [],
      "source": [
        "# # Install any required libraries not present in your working environment\n",
        "\n",
        "if install_required_packages:\n",
        "    # # Needed locally and in colab\n",
        "    # !pip install torchsummary\n",
        "    # !conda install -c frgfm torchscan\n",
        "\n",
        "    import sys\n",
        "    !{sys.executable} -m pip install torchsummary\n",
        "\n",
        "    if model_run_location == 'colab':\n",
        "        !{sys.executable} -m pip install albumentations\n",
        "\n",
        "    # # Needed locally\n",
        "    # !conda install -c conda-forge tqdm\n",
        "    # !conda install -c anaconda ipywidgets\n",
        "\n",
        "    if model_run_location == 'local':\n",
        "        %conda install --yes --prefix {sys.prefix} -c conda-forge tqdm\n",
        "        %conda install --yes --prefix {sys.prefix} -c anaconda ipywidgets\n",
        "        %conda install --yes --prefix {sys.prefix} -c conda-forge imgaug\n",
        "        %conda install --yes --prefix {sys.prefix} -c conda-forge albumentations\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "W4vt-IWCaJwx"
      },
      "source": [
        "## Mount Drive\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cJHG1vnqaJwx",
        "outputId": "cf924cc5-98db-4b5a-8227-1646ef1eabc3"
      },
      "outputs": [],
      "source": [
        "# Mount google drive if running on colab\n",
        "if model_run_location == 'colab':\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "    %cd /content/drive/MyDrive/WorkSpace/era-v1/Session 09/Submission"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "jiWmJROnaJwy"
      },
      "source": [
        "## Import Libraries\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "6PlbomWY3RSq"
      },
      "outputs": [],
      "source": [
        "# Import necessary modules (external libs)\n",
        "from __future__ import print_function\n",
        "\n",
        "import albumentations as A\n",
        "# Needed for padding issues in albumentations\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from albumentations.pytorch.transforms import ToTensorV2\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "from torchsummary import summary\n",
        "from torchvision import transforms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "WGMvMPH-aJwz"
      },
      "outputs": [],
      "source": [
        "# Import user defined modules\n",
        "from dataset import split_cifar_data\n",
        "from model import Assignment9 as Net\n",
        "from model import test_model, train_model\n",
        "from utils import get_device, save_model\n",
        "from visualize import (\n",
        "    plot_misclassified_images,\n",
        "    plot_sample_training_images,\n",
        "    plot_train_test_metrics,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "94BxVVBP3WwS",
        "outputId": "63dc9256-4d7c-4d71-d1f0-587a7f1ac275"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Device created with cuda!\n"
          ]
        }
      ],
      "source": [
        "# Functionality to check cuda support and create device is now moved to utils.py\n",
        "device_support, device = get_device()\n",
        "print(f\"Device created with {device_support}!\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "IQHWl11waJw1"
      },
      "source": [
        "## Data Transformations\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "KpshQ2Ug38m2"
      },
      "outputs": [],
      "source": [
        "# Train and test data transformation steps now moved to apply_mnist_image_transformations()\n",
        "\n",
        "# Use precomputed values for mean and standard deviation of the dataset\n",
        "cifar_mean = (0.4915, 0.4823, 0.4468)\n",
        "cifar_std = (0.2470, 0.2435, 0.2616)\n",
        "\n",
        "# cutout needs to be half of the image size\n",
        "cutout_size = 16\n",
        "\n",
        "\n",
        "def apply_cifar_image_transformations():\n",
        "    \"\"\"\n",
        "    Function to apply the required transformations to the MNIST dataset.\n",
        "    \"\"\"\n",
        "    # Apply the required transformations to the MNIST dataset\n",
        "    train_transforms = A.Compose(\n",
        "        [\n",
        "            # https://albumentations.ai/docs/api_reference/augmentations/geometric/transforms/#albumentations.augmentations.geometric.transforms.HorizontalFlip\n",
        "            A.HorizontalFlip(),\n",
        "            # https://albumentations.ai/docs/api_reference/augmentations/geometric/transforms/#albumentations.augmentations.geometric.transforms.ShiftScaleRotate\n",
        "            A.ShiftScaleRotate(\n",
        "                shift_limit=0.1, scale_limit=0.2, rotate_limit=10, p=0.5\n",
        "            ),\n",
        "            # # https://albumentations.ai/docs/api_reference/augmentations/geometric/transforms/#albumentations.augmentations.geometric.transforms.PadIfNeeded\n",
        "            # # https://answers.opencv.org/question/50706/border_reflect-vs-border_reflect_101/\n",
        "            # A.PadIfNeeded(\n",
        "            #     min_height=40, min_width=40, border_mode=cv2.BORDER_REFLECT_101, p=1\n",
        "            # ),\n",
        "            # https://albumentations.ai/docs/api_reference/augmentations/dropout/coarse_dropout/#coarsedropout-augmentation-augmentationsdropoutcoarse_dropout\n",
        "            A.CoarseDropout(\n",
        "                max_holes=1,\n",
        "                max_height=cutout_size,\n",
        "                max_width=cutout_size,\n",
        "                min_holes=1,\n",
        "                min_height=cutout_size,\n",
        "                min_width=cutout_size,\n",
        "                fill_value=list(cifar_mean),\n",
        "                mask_fill_value=None,\n",
        "            ),\n",
        "            # # https://albumentations.ai/docs/api_reference/augmentations/dropout/cutout/#cutout-augmentation-augmentationsdropoutcutout\n",
        "            # A.Cutout(\n",
        "            #     max_h_size=cutout_size,\n",
        "            #     max_w_size=cutout_size,\n",
        "            #     num_holes=1,\n",
        "            #     fill_value = cifar_mean)\n",
        "            # normalize the images with mean and standard deviation from the whole dataset\n",
        "            # https://albumentations.ai/docs/api_reference/augmentations/transforms/#albumentations.augmentations.transforms.Normalize\n",
        "            # # transforms.Normalize(cifar_mean, cifar_std),\n",
        "            A.Normalize(mean=list(cifar_mean), std=list(cifar_std)),\n",
        "            # Convert the images to tensors\n",
        "            # # transforms.ToTensor(),\n",
        "            ToTensorV2(),\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    # Test data transformations\n",
        "    test_transforms = A.Compose(\n",
        "        # Convert the images to tensors\n",
        "        # normalize the images with mean and standard deviation from the whole dataset\n",
        "        [\n",
        "            A.Normalize(mean=list(cifar_mean), std=list(cifar_std)),\n",
        "            # Convert the images to tensors\n",
        "            ToTensorV2(),\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    return train_transforms, test_transforms\n",
        "\n",
        "\n",
        "train_transforms, test_transforms = apply_cifar_image_transformations()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "3VAgkx0VaJw3"
      },
      "source": [
        "## Train/Test Split\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JB79ZYW13-AO",
        "outputId": "b3550507-cbdf-4c1b-aa47-90777670b217"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train and test data path: ../../data\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Mean: [0.4914009  0.48215896 0.4465308 ]\n",
            "Std: [0.24703279 0.24348423 0.26158753]\n",
            "\n",
            "Transforms applied on the dataset\n",
            "\n"
          ]
        }
      ],
      "source": [
        "data_path = \"../../data\"\n",
        "print(f\"Train and test data path: {data_path}\")\n",
        "\n",
        "train_data, test_data = split_cifar_data(data_path, train_transforms, test_transforms)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "to2chNEdaJw4"
      },
      "source": [
        "## Dataloaders\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "d8lov1SaaJw4"
      },
      "outputs": [],
      "source": [
        "# Set seed value for reproducibility\n",
        "seed = 8\n",
        "\n",
        "# For reproducibility\n",
        "torch.manual_seed(seed)\n",
        "\n",
        "if device_support == \"cuda\":\n",
        "    torch.cuda.manual_seed(seed)\n",
        "\n",
        "batch_size = 128\n",
        "\n",
        "# calculate the number of workers\n",
        "num_workers = (os.cpu_count() - 1) if os.cpu_count() > 3 else 2\n",
        "\n",
        "# dataloader arguments - something you'll fetch these from cmdprmt\n",
        "dataloader_args = dict(\n",
        "    shuffle=True, batch_size=batch_size, num_workers=num_workers, pin_memory=True\n",
        ")\n",
        "\n",
        "# train dataloader\n",
        "train_loader = torch.utils.data.DataLoader(train_data, **dataloader_args)\n",
        "\n",
        "# test dataloader\n",
        "test_loader = torch.utils.data.DataLoader(test_data, **dataloader_args)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ONtvq4itTpcE",
        "outputId": "6f8ca65f-81fe-4c45-99de-2a41552e0dc7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "('Plane', 'Car', 'Bird', 'Cat', 'Deer', 'Dog', 'Frog', 'Horse', 'Ship', 'Truck')\n"
          ]
        }
      ],
      "source": [
        "# Create class labels\n",
        "classes = [\n",
        "    \"plane\",\n",
        "    \"car\",\n",
        "    \"bird\",\n",
        "    \"cat\",\n",
        "    \"deer\",\n",
        "    \"dog\",\n",
        "    \"frog\",\n",
        "    \"horse\",\n",
        "    \"ship\",\n",
        "    \"truck\",\n",
        "]\n",
        "\n",
        "# Convert classes to propercase\n",
        "classes = tuple([c.capitalize() for c in classes])\n",
        "print(classes)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "3tcyJZ7xaJw4"
      },
      "source": [
        "## Sample Training Images\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 983
        },
        "id": "Hx7QkLcw4Epc",
        "outputId": "2516b880-05f9-45a2-9467-1e7eb224bdf4"
      },
      "outputs": [],
      "source": [
        "# Get a batch of training data from train_loader\n",
        "batch_data, batch_label = next(iter(train_loader))\n",
        "\n",
        "# Plot 30 sample images from the training data along with their labels\n",
        "# plot_sample_training_images() imported from utils.py\n",
        "fig, axs = plot_sample_training_images(\n",
        "    batch_data, batch_label, class_label=classes, num_images=30\n",
        ")\n",
        "plt.show()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "dtKTHaq3aJw5"
      },
      "source": [
        "## Model Summary\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_D2fZQC2aJw6",
        "outputId": "e4a54804-a3b6-4b51-f39e-863cb5dcc8de"
      },
      "outputs": [],
      "source": [
        "# Model class is imported from model.py\n",
        "\n",
        "# Send the model to device\n",
        "model = Net(normalization_method=\"batch\").to(device)\n",
        "\n",
        "# enable printing shape\n",
        "model.print_shape = True\n",
        "\n",
        "# Print the model summary by specifying the input size\n",
        "summary(model, input_size=(3, 32, 32))\n",
        "\n",
        "# disable printing shape for cleaner test train output\n",
        "model.print_shape = False"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Hmz3iF8YaJw6"
      },
      "source": [
        "## Metric Initialisation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7du4zM474LvT"
      },
      "outputs": [],
      "source": [
        "# Data to plot accuracy and loss graphs\n",
        "\n",
        "# Hold test and train losses in a list\n",
        "train_losses = []\n",
        "test_losses = []\n",
        "# Hold test and train accuracies in a list\n",
        "train_acc = []\n",
        "test_acc = []\n",
        "# Create a dictionary of lists for misclassified images, generated predictions and ground truth\n",
        "misclassified_image_data = {\"images\": [], \"ground_truths\": [], \"predicted_vals\": []}"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "ZZC5UXwXaJw7"
      },
      "source": [
        "## Train and Test\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Owqiet9M4TV7",
        "outputId": "b59b4570-4a15-4b45-b8d5-b919b28d44e9"
      },
      "outputs": [],
      "source": [
        "# Create optimizer and scheduler\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
        "\n",
        "# Define criteria function\n",
        "criterion = F.nll_loss\n",
        "\n",
        "# Learning rate scheduler based on plateau\n",
        "# https://pytorch.org/docs/stable/generated/torch.optim.lr_scheduler.ReduceLROnPlateau.html\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
        "    optimizer, mode=\"min\", factor=0.5, patience=1, threshold=0.03, verbose=False\n",
        ")\n",
        "\n",
        "# Specify the number of epochs\n",
        "num_epochs = 20\n",
        "\n",
        "for epoch in range(1, num_epochs + 1):\n",
        "    if epoch == 1:\n",
        "        print(f\"\\n\\nBatch size: {batch_size}, Total epochs: {num_epochs}\\n\\n\")\n",
        "\n",
        "    # Print the current epoch\n",
        "    print(f\"Epoch {epoch}\")\n",
        "    # Train the model\n",
        "    train_model(\n",
        "        model, device, train_loader, optimizer, criterion, train_acc, train_losses\n",
        "    )\n",
        "    # Test the model\n",
        "    test_model(\n",
        "        model,\n",
        "        device,\n",
        "        test_loader,\n",
        "        criterion,\n",
        "        test_acc,\n",
        "        test_losses,\n",
        "        misclassified_image_data,\n",
        "    )\n",
        "\n",
        "    # Check if the accuracy is the best accuracy till now\n",
        "    # Save the model if you get the best test accuracy\n",
        "    if max(test_acc) == test_acc[-1]:\n",
        "        save_model(\n",
        "            epoch,\n",
        "            model,\n",
        "            optimizer,\n",
        "            scheduler,\n",
        "            batch_size,\n",
        "            criterion,\n",
        "            file_name=\"model_best_epoch.pth\",\n",
        "        )\n",
        "\n",
        "    # Passing the latest test loss in list to scheduler to adjust learning rate\n",
        "    scheduler.step(test_losses[-1])\n",
        "    # Line break before next epoch\n",
        "    print(\"\\n\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "8epmHZIPaJw7"
      },
      "source": [
        "## Metrics\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 853
        },
        "id": "Wu0l7dli4eC9",
        "outputId": "d86f7eac-b620-4692-a721-13a4eddcb4b5"
      },
      "outputs": [],
      "source": [
        "# Plot the accuracy and loss graphs using data and plot_train_test_metrics() from model.py\n",
        "fig, axs = plot_train_test_metrics(train_losses, train_acc, test_losses, test_acc)\n",
        "plt.show()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "xvSpV2XLjEhb"
      },
      "source": [
        "## Save model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fSoN5DVhjEhb"
      },
      "outputs": [],
      "source": [
        "# Save model\n",
        "save_model(\n",
        "    epoch,\n",
        "    model,\n",
        "    optimizer,\n",
        "    scheduler,\n",
        "    batch_size,\n",
        "    criterion,\n",
        "    file_name=\"model_last_epoch.pth\",\n",
        ")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "PFUaX9XkTpcI"
      },
      "source": [
        "## Show incorrect images\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "id": "X5131GVbTpcJ",
        "outputId": "880d756f-819f-4101-8234-f0c62eb4d1df"
      },
      "outputs": [],
      "source": [
        "# Plot misclassified images\n",
        "fig, axs = plot_misclassified_images(\n",
        "    data=misclassified_image_data, class_label=classes, num_images=10\n",
        ")\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
