{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bw8mN4mWaJwt"
      },
      "source": [
        "# Assignment 10 - Viraj Noorithaya\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i5EJaJ6PaJwu"
      },
      "source": [
        "## Script Parameters\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "cm_GkK-maJwv"
      },
      "outputs": [],
      "source": [
        "# Where are you running this? Can be either 'local' or 'colab'\n",
        "model_run_location = \"colab\"\n",
        "\n",
        "# # Do you want to install the required packages?\n",
        "# install_required_packages = False\n",
        "install_required_packages = False if model_run_location == \"local\" else True\n",
        "\n",
        "# git repository url\n",
        "git_repo_url = \"https://github.com/nviraj/era-v1.git\"\n",
        "\n",
        "# Is the model being developed or is it in production?\n",
        "# Can be development or production\n",
        "code_mode = \"development\"\n",
        "\n",
        "# WHich branch are you working on?\n",
        "branch_name = \"week-10\" if code_mode == \"development\" else \"main\"\n",
        "folder_name = \"Session 10/Submission\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TEku13Z9uGHX"
      },
      "source": [
        "## Library Installation (Optional)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ehhA4GGpaJww",
        "outputId": "70d427c4-bb21-4246-9085-a688cefff488"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torchsummary in /usr/local/lib/python3.10/dist-packages (1.5.1)\n",
            "Collecting torch-lr-finder\n",
            "  Downloading torch_lr_finder-0.2.1-py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from torch-lr-finder) (3.7.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch-lr-finder) (1.22.4)\n",
            "Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from torch-lr-finder) (2.0.1+cu118)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch-lr-finder) (4.65.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from torch-lr-finder) (23.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.1->torch-lr-finder) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.1->torch-lr-finder) (4.7.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.1->torch-lr-finder) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.1->torch-lr-finder) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.1->torch-lr-finder) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.1->torch-lr-finder) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=0.4.1->torch-lr-finder) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=0.4.1->torch-lr-finder) (16.0.6)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->torch-lr-finder) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->torch-lr-finder) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->torch-lr-finder) (4.41.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->torch-lr-finder) (1.4.4)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->torch-lr-finder) (8.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->torch-lr-finder) (3.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->torch-lr-finder) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->torch-lr-finder) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=0.4.1->torch-lr-finder) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=0.4.1->torch-lr-finder) (1.3.0)\n",
            "Installing collected packages: torch-lr-finder\n",
            "Successfully installed torch-lr-finder-0.2.1\n"
          ]
        }
      ],
      "source": [
        "# # Install any required libraries not present in your working environment\n",
        "\n",
        "if install_required_packages:\n",
        "    # # Needed locally and in colab\n",
        "    # !pip install torchsummary\n",
        "    # !conda install -c frgfm torchscan\n",
        "\n",
        "    import sys\n",
        "    !{sys.executable} -m pip install torchsummary\n",
        "    !{sys.executable} -m pip install torch-lr-finder\n",
        "\n",
        "    # if model_run_location == 'colab':\n",
        "    #     !{sys.executable} -m pip install albumentations\n",
        "\n",
        "    # # Needed locally\n",
        "    # !conda install -c conda-forge tqdm\n",
        "    # !conda install -c anaconda ipywidgets\n",
        "\n",
        "    if model_run_location == 'local':\n",
        "        %conda install --yes --prefix {sys.prefix} -c conda-forge tqdm\n",
        "        %conda install --yes --prefix {sys.prefix} -c anaconda ipywidgets\n",
        "        %conda install --yes --prefix {sys.prefix} -c conda-forge imgaug\n",
        "        %conda install --yes --prefix {sys.prefix} -c conda-forge albumentations\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W4vt-IWCaJwx"
      },
      "source": [
        "## Code Procurement\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cJHG1vnqaJwx",
        "outputId": "c3a62623-818f-4772-b52d-77b53159afad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'era-v1'...\n",
            "remote: Enumerating objects: 988, done.\u001b[K\n",
            "remote: Counting objects: 100% (4/4), done.\u001b[K\n",
            "remote: Compressing objects: 100% (4/4), done.\u001b[K\n",
            "remote: Total 988 (delta 0), reused 0 (delta 0), pack-reused 984\u001b[K\n",
            "Receiving objects: 100% (988/988), 6.42 MiB | 15.33 MiB/s, done.\n",
            "Resolving deltas: 100% (493/493), done.\n",
            "Branch 'week-10' set up to track remote branch 'week-10' from 'origin'.\n",
            "Switched to a new branch 'week-10'\n"
          ]
        }
      ],
      "source": [
        "# Mount google drive if running on colab\n",
        "if model_run_location == 'colab':\n",
        "    # from google.colab import drive\n",
        "    # drive.mount('/content/drive')\n",
        "    # %cd /content/drive/MyDrive/WorkSpace/era-v1/Session 10/Submission\n",
        "\n",
        "    # Delete the folder if it exists\n",
        "    # Avoids fatal: destination path already exists and is not an empty directory.\n",
        "    # Get code from github\n",
        "    !rm -rf \"era-v1\" && git clone {git_repo_url}\n",
        "\n",
        "    # Switch to repo folder, Needed to switch branch\n",
        "    # Switch branch and change to the correct directory\n",
        "    !cd \"era-v1\" && git checkout {branch_name} && cd \"{folder_name}\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jiWmJROnaJwy"
      },
      "source": [
        "## Import Libraries\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "6PlbomWY3RSq",
        "outputId": "87c36334-eebf-40e1-d22d-ad72dca308b7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch_lr_finder/lr_finder.py:5: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
            "  from tqdm.autonotebook import tqdm\n"
          ]
        }
      ],
      "source": [
        "# Import necessary modules (external libs)\n",
        "import os\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.optim.lr_scheduler import OneCycleLR\n",
        "from torch_lr_finder import LRFinder\n",
        "from torchsummary import summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "WGMvMPH-aJwz",
        "outputId": "a2209d85-1802-4690-ca1b-472fef68b468",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-282f6c479689>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Import user defined modules\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msplit_cifar_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapply_cifar_image_transformations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCIFAR_MEAN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCIFAR_STD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCIFAR_CLASSES\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcustom_resnet\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCustomResNet\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mNet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain_and_test_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'modules'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "# Import user defined modules\n",
        "from modules.dataset import split_cifar_data, apply_cifar_image_transformations\n",
        "from modules.dataset import CIFAR_MEAN, CIFAR_STD, CIFAR_CLASSES\n",
        "from modules.custom_resnet import CustomResNet as Net\n",
        "from modules.trainer import train_and_test_model\n",
        "from modules.utils import get_device, save_model, pretty_print_metrics\n",
        "from modules.visualize import (\n",
        "    plot_misclassified_images,\n",
        "    plot_sample_training_images,\n",
        "    plot_train_test_metrics,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U71ZcO2yuGHb"
      },
      "source": [
        "## Script Parameters\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KxqJvgkiuGHc"
      },
      "outputs": [],
      "source": [
        "# Constants naming convention: All caps separated by underscore\n",
        "# https://realpython.com/python-constants/\n",
        "\n",
        "# Specify the number of epochs\n",
        "NUM_EPOCHS = 24\n",
        "\n",
        "# Set the batch size\n",
        "BATCH_SIZE = 512\n",
        "\n",
        "# Set seed value for reproducibility\n",
        "SEED = 8\n",
        "\n",
        "# Expected accuracy\n",
        "TARGET_ACCURACY = 90.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6hdO0QPWuGHd"
      },
      "source": [
        "## Get Device\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "94BxVVBP3WwS"
      },
      "outputs": [],
      "source": [
        "# Functionality to check cuda support and create device is now moved to utils.py\n",
        "device_support, device = get_device()\n",
        "print(f\"Device created with {device_support}!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IQHWl11waJw1"
      },
      "source": [
        "## Data Transformations\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KpshQ2Ug38m2"
      },
      "outputs": [],
      "source": [
        "# Train and test data transformation steps now moved to apply_mnist_image_transformations()\n",
        "\n",
        "# cutout needs to be half of the image size\n",
        "cutout_size = 8\n",
        "\n",
        "train_transforms, test_transforms = apply_cifar_image_transformations(\n",
        "    mean=CIFAR_MEAN, std=CIFAR_STD, cutout_size=cutout_size\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3VAgkx0VaJw3"
      },
      "source": [
        "## Train/Test Split\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JB79ZYW13-AO"
      },
      "outputs": [],
      "source": [
        "data_path = \"../../data\"\n",
        "print(f\"Train and test data path: {data_path}\")\n",
        "\n",
        "train_data, test_data = split_cifar_data(data_path, train_transforms, test_transforms)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "to2chNEdaJw4"
      },
      "source": [
        "## Dataloaders\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d8lov1SaaJw4"
      },
      "outputs": [],
      "source": [
        "# For reproducibility\n",
        "torch.manual_seed(SEED)\n",
        "\n",
        "if device_support == \"cuda\":\n",
        "    torch.cuda.manual_seed(SEED)\n",
        "\n",
        "# calculate the number of workers\n",
        "num_workers = (os.cpu_count() - 1) if os.cpu_count() > 3 else 2\n",
        "\n",
        "# dataloader arguments - something you'll fetch these from cmdprmt\n",
        "dataloader_args = dict(\n",
        "    shuffle=True, BATCH_SIZE=BATCH_SIZE, num_workers=num_workers, pin_memory=True\n",
        ")\n",
        "\n",
        "# train dataloader\n",
        "train_loader = torch.utils.data.DataLoader(train_data, **dataloader_args)\n",
        "\n",
        "# test dataloader\n",
        "test_loader = torch.utils.data.DataLoader(test_data, **dataloader_args)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ONtvq4itTpcE"
      },
      "outputs": [],
      "source": [
        "# Get class mapping for the dataset\n",
        "classes = CIFAR_CLASSES\n",
        "print(classes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3tcyJZ7xaJw4"
      },
      "source": [
        "## Sample Training Images\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hx7QkLcw4Epc"
      },
      "outputs": [],
      "source": [
        "# Get a batch of training data from train_loader\n",
        "batch_data, batch_label = next(iter(train_loader))\n",
        "\n",
        "# Plot 30 sample images from the training data along with their labels\n",
        "# plot_sample_training_images() imported from utils.py\n",
        "fig, axs = plot_sample_training_images(\n",
        "    batch_data, batch_label, class_label=classes, num_images=30\n",
        ")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dtKTHaq3aJw5"
      },
      "source": [
        "## Model Summary\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_D2fZQC2aJw6"
      },
      "outputs": [],
      "source": [
        "# Model class is imported from model.py\n",
        "\n",
        "# Send the model to device\n",
        "model = Net().to(device)\n",
        "\n",
        "# enable printing shape\n",
        "model.print_shape = True\n",
        "\n",
        "# Print the model summary by specifying the input size\n",
        "summary(model, input_size=(3, 32, 32))\n",
        "\n",
        "# disable printing shape for cleaner test train output\n",
        "model.print_shape = False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZZC5UXwXaJw7"
      },
      "source": [
        "## Train and Test\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kuPeac4MuGHh"
      },
      "source": [
        "### Optimizer and Loss Function\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Owqiet9M4TV7"
      },
      "outputs": [],
      "source": [
        "# Create optimizer and scheduler\n",
        "# Use ADAM\n",
        "# https://pytorch.org/docs/stable/generated/torch.optim.Adam.html\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-2, weight_decay=0)\n",
        "\n",
        "# Define criteria function\n",
        "# https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html\n",
        "criterion = torch.nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NAUZpitAuGHh"
      },
      "source": [
        "### Find Learning Rate\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "37nW5EIEuGHh"
      },
      "outputs": [],
      "source": [
        "# Use LR Finder to find the best starting learning rate\n",
        "# https://github.com/davidtvs/pytorch-lr-finder\n",
        "# https://github.com/davidtvs/pytorch-lr-finder#notes\n",
        "\n",
        "# Create LR finder object\n",
        "lr_finder = LRFinder(model, optimizer, criterion, device=device)\n",
        "lr_finder.range_test(train_loader=train_loader, end_lr=10, num_iter=100)\n",
        "plot, optimal_lr = lr_finder.plot(suggest_lr=True)\n",
        "lr_finder.reset()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pUMgrmnYuGHh"
      },
      "source": [
        "### Scheduler\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uyP_d0sxuGHh"
      },
      "outputs": [],
      "source": [
        "# # Learning rate scheduler based on plateau\n",
        "# # https://pytorch.org/docs/stable/generated/torch.optim.lr_scheduler.ReduceLROnPlateau.html\n",
        "# scheduler = ReduceLROnPlateau(\n",
        "#     optimizer, mode=\"min\", factor=0.5, patience=1, threshold=0.03, verbose=False\n",
        "# )\n",
        "\n",
        "# Learning rate scheduler based on OneCycleLR\n",
        "# https://pytorch.org/docs/stable/generated/torch.optim.lr_scheduler.OneCycleLR.html\n",
        "scheduler = OneCycleLR(\n",
        "    optimizer,\n",
        "    max_lr=optimal_lr,\n",
        "    steps_per_epoch=len(train_loader),\n",
        "    epochs=NUM_EPOCHS,\n",
        "    pct_start=5 / NUM_EPOCHS,\n",
        "    div_factor=100,\n",
        "    three_phase=False,\n",
        "    final_div_factor=100,\n",
        "    anneal_strategy=\"linear\",\n",
        "    verbose=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZymIecrUuGHi"
      },
      "source": [
        "### Train and test model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AgiHs--euGHi"
      },
      "outputs": [],
      "source": [
        "# Create a dictionary of lists for misclassified images, generated predictions and ground truth\n",
        "misclassified_image_data = {\"images\": [], \"ground_truths\": [], \"predicted_vals\": []}\n",
        "\n",
        "# Run the model for NUM_EPOCHS\n",
        "results = train_and_test_model(\n",
        "    batch_size=BATCH_SIZE,\n",
        "    num_epochs=NUM_EPOCHS,\n",
        "    model=model,\n",
        "    device=device,\n",
        "    train_loader=train_loader,\n",
        "    test_loader=test_loader,\n",
        "    optimizer=optimizer,\n",
        "    criterion=criterion,\n",
        "    scheduler=scheduler,\n",
        "    misclassified_image_data=misclassified_image_data,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ojgiBmmcaeO1"
      },
      "outputs": [],
      "source": [
        "# Pretty print train and test accuracy and loss values for each epoch\n",
        "pretty_print_metrics(num_epochs = NUM_EPOCHS, results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8epmHZIPaJw7"
      },
      "source": [
        "## Metrics\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wu0l7dli4eC9"
      },
      "outputs": [],
      "source": [
        "# Print expected accuracy for easier reference\n",
        "print(f\"Expected accuracy: {TARGET_ACCURACY}%\")\n",
        "\n",
        "# Plot the accuracy and loss graphs using data and plot_train_test_metrics() from model.py\n",
        "print(\"Plotting accuracy and loss graphs.\")\n",
        "fig, axs = plot_train_test_metrics(results)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xvSpV2XLjEhb"
      },
      "source": [
        "## Save model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fSoN5DVhjEhb"
      },
      "outputs": [],
      "source": [
        "# Save model\n",
        "print(\"Saving the model as the training is complete!\")\n",
        "save_model(\n",
        "    epoch,\n",
        "    model,\n",
        "    optimizer,\n",
        "    scheduler,\n",
        "    batch_size = BATCH_SIZE,\n",
        "    criterion,\n",
        "    file_name=\"model_last_epoch.pth\",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PFUaX9XkTpcI"
      },
      "source": [
        "## Show incorrect images\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X5131GVbTpcJ"
      },
      "outputs": [],
      "source": [
        "# Plot misclassified images\n",
        "fig, axs = plot_misclassified_images(\n",
        "    data=misclassified_image_data, class_label=classes, num_images=10\n",
        ")\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}